{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Computer Vision, Skoltech, 2021\n",
    "#### Alexey Artemov, Aleksandr Safin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import k3d\n",
    "import imageio\n",
    "from skimage import measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSDF Fusion in brief\n",
    "\n",
    "For every new observation $O_{i+1}$\n",
    "- RGBD to point cloud\n",
    "- TSDF creation from one RGBD\n",
    "- Integrate TSDF for $O_{i+1}$ with current TSDF\n",
    "   - You need to weight appropriately \n",
    "\n",
    "Afterall run marshing cubes on your TSDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Notes:\n",
    "\n",
    "Volume bounds are in meters, depth also should be specified in meters\n",
    "\n",
    "You should use the following intrinsics matrix for the camera:\n",
    "```\n",
    "array([[525. ,   0. , 319.5],\n",
    "       [  0. , 525. , 239.5],\n",
    "       [  0. ,   0. ,   1. ]])\n",
    "```\n",
    "\n",
    "ans with width = 640 and height = 480."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redwood Data\n",
    "\n",
    "Here we will use a part of [Redwood indoor RGBD dataset](http://redwood-data.org/indoor_lidar_rgbd/)\n",
    "\n",
    "RGBD are in ``sample_data/redwood_samples`.\n",
    "\n",
    "Extrinsics are in `sample_data/poses.npy`, use `np.load` to open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSDFVolume:\n",
    "    \"\"\"\n",
    "        Volumetric TSDF Fusion of RGB-D Images.\n",
    "    \"\"\"\n",
    "    def __init__(self, vol_bnds, voxel_size):\n",
    "        \"\"\"Constructor.\n",
    "        Args:\n",
    "          vol_bnds (ndarray): An ndarray of shape (3, 2). Specifies the\n",
    "            xyz bounds (min/max) in meters.\n",
    "          voxel_size (float): The volume discretization in meters.\n",
    "        \"\"\"\n",
    "        vol_bnds = np.asarray(vol_bnds)\n",
    "        assert vol_bnds.shape == (3, 2), \"[!] `vol_bnds` should be of shape (3, 2).\"\n",
    "\n",
    "        # Define voxel volume parameters\n",
    "        self._vol_bnds = vol_bnds\n",
    "        self._voxel_size = float(voxel_size)\n",
    "        self._trunc_margin = 10 * self._voxel_size  # truncation on SDF\n",
    "\n",
    "        # Adjust volume bounds and ensure C-order contiguous\n",
    "        self._vol_dim = np.ceil((self._vol_bnds[:,1]-self._vol_bnds[:,0])/self._voxel_size).copy(order='C').astype(int)\n",
    "        self._vol_bnds[:,1] = self._vol_bnds[:,0] + self._vol_dim*self._voxel_size\n",
    "        self._vol_origin = self._vol_bnds[:,0].copy(order='C').astype(np.float32)\n",
    "\n",
    "        print(\"Voxel volume size: {} x {} x {} - # points: {:,}\".format(\n",
    "          self._vol_dim[0], self._vol_dim[1], self._vol_dim[2],\n",
    "          self._vol_dim[0]*self._vol_dim[1]*self._vol_dim[2])\n",
    "        )\n",
    "\n",
    "        # Initialize voxel volume\n",
    "        self._tsdf_vol = np.ones(self._vol_dim).astype(np.float32)\n",
    "        # for computing the cumulative moving average of observations per voxel\n",
    "        self._weight_vol = np.zeros(self._vol_dim).astype(np.float32)\n",
    "\n",
    "        # Get voxel grid coordinates\n",
    "        xv, yv, zv = np.meshgrid(\n",
    "            range(self._vol_dim[0]),\n",
    "            range(self._vol_dim[1]),\n",
    "            range(self._vol_dim[2]),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        self.vox_coords = np.concatenate([\n",
    "            xv.reshape(1,-1),\n",
    "            yv.reshape(1,-1),\n",
    "            zv.reshape(1,-1)\n",
    "        ], axis=0).astype(int).T\n",
    "\n",
    "    @staticmethod\n",
    "    def vox2world(vol_origin, vox_coords, vox_size):\n",
    "        \"\"\"\n",
    "            Convert voxel grid coordinates to world coordinates.\n",
    "        \"\"\"\n",
    "        vol_origin = vol_origin.astype(np.float32)\n",
    "        vox_coords = vox_coords.astype(np.float32)\n",
    "        cam_pts = np.empty_like(vox_coords, dtype=np.float32)\n",
    "        for i in range(vox_coords.shape[0]):\n",
    "            for j in range(3):\n",
    "                cam_pts[i, j] = vol_origin[j] + (vox_size * vox_coords[i, j])\n",
    "        return cam_pts\n",
    "\n",
    "    @staticmethod\n",
    "    def cam2pix(cam_pts, intr):\n",
    "        \"\"\"\n",
    "            Convert camera coordinates to pixel coordinates.\n",
    "        \"\"\"\n",
    "        intr = intr.astype(np.float32)\n",
    "        fx, fy = intr[0, 0], intr[1, 1]\n",
    "        cx, cy = intr[0, 2], intr[1, 2]\n",
    "        pix = np.empty((cam_pts.shape[0], 2), dtype=np.int64)\n",
    "        for i in range(cam_pts.shape[0]):\n",
    "            pix[i, 0] = int(np.round((cam_pts[i, 0] * fx / cam_pts[i, 2]) + cx))\n",
    "            pix[i, 1] = int(np.round((cam_pts[i, 1] * fy / cam_pts[i, 2]) + cy))\n",
    "        return pix\n",
    "\n",
    "    @staticmethod\n",
    "    def integrate_next_obs_tsdf(tsdf_vol, dist, w_old, obs_weight):\n",
    "        \"\"\"\n",
    "            Integrate the TSDF volume.\n",
    "            Agrs:\n",
    "                tsdf_vol: Accumulated TSDF\n",
    "                dist: TSDF for current observation\n",
    "            Returns:\n",
    "                tsdf_vol_int: Fused new accumulated TSDF\n",
    "                w_new: updated new W_{i+1}\n",
    "        \"\"\"\n",
    "        tsdf_vol_int = np.empty_like(tsdf_vol, dtype=np.float32)\n",
    "        w_new = np.empty_like(w_old, dtype=np.float32)\n",
    "\n",
    "        \"\"\"\n",
    "            Update tsdf_vol_int and w_new\n",
    "        \"\"\"\n",
    "        return tsdf_vol_int, w_new\n",
    "\n",
    "    def integrate(self, color_im, depth_im, cam_intr, cam_pose, obs_weight=1.):\n",
    "        \"\"\"Integrate an RGB-D frame into the TSDF volume.\n",
    "        Args:\n",
    "          color_im (ndarray): An RGB image of shape (H, W, 3).\n",
    "          depth_im (ndarray): A depth image of shape (H, W).\n",
    "          cam_intr (ndarray): The camera intrinsics matrix of shape (3, 3).\n",
    "          cam_pose (ndarray): The camera pose (i.e. extrinsics) of shape (4, 4).\n",
    "          obs_weight (float): The weight to assign for the current observation.\n",
    "        \"\"\"\n",
    "        im_h, im_w = depth_im.shape\n",
    "\n",
    "        # Convert voxel grid coordinates to pixel coordinates\n",
    "        cam_pts = self.vox2world(self._vol_origin, self.vox_coords, self._voxel_size)\n",
    "        cam_pts = rigid_transform(cam_pts, np.linalg.inv(cam_pose))\n",
    "        pix_z = cam_pts[:, 2]\n",
    "        pix = self.cam2pix(cam_pts, cam_intr)\n",
    "        pix_x, pix_y = pix[:, 0], pix[:, 1]\n",
    "\n",
    "        # Eliminate pixels outside view frustum\n",
    "        valid_pix = np.logical_and(pix_x >= 0,\n",
    "                  np.logical_and(pix_x < im_w,\n",
    "                  np.logical_and(pix_y >= 0,\n",
    "                  np.logical_and(pix_y < im_h,\n",
    "                  pix_z > 0))))\n",
    "        depth_val = np.zeros(pix_x.shape)\n",
    "        depth_val[valid_pix] = depth_im[pix_y[valid_pix], pix_x[valid_pix]]\n",
    "\n",
    "        # Integrate TSDF\n",
    "        depth_diff = depth_val - pix_z\n",
    "        valid_pts = np.logical_and(depth_val > 0, depth_diff >= -self._trunc_margin)\n",
    "        dist = np.minimum(1, depth_diff / self._trunc_margin)\n",
    "        valid_vox_x = self.vox_coords[valid_pts, 0]\n",
    "        valid_vox_y = self.vox_coords[valid_pts, 1]\n",
    "        valid_vox_z = self.vox_coords[valid_pts, 2]\n",
    "        w_old = self._weight_vol[valid_vox_x, valid_vox_y, valid_vox_z]\n",
    "        tsdf_vals = self._tsdf_vol[valid_vox_x, valid_vox_y, valid_vox_z]\n",
    "        valid_dist = dist[valid_pts]\n",
    "        \n",
    "        # Here you weight appropriately accumulated TSDF and TSDF for current observation\n",
    "        tsdf_vol_new, w_new = self.integrate_next_obs_tsdf(tsdf_vals, valid_dist, w_old, obs_weight)\n",
    "        \n",
    "        self._weight_vol[valid_vox_x, valid_vox_y, valid_vox_z] = w_new\n",
    "        self._tsdf_vol[valid_vox_x, valid_vox_y, valid_vox_z] = tsdf_vol_new\n",
    "\n",
    "    def get_volume(self):\n",
    "        return self._tsdf_vol\n",
    "\n",
    "    def get_mesh(self):\n",
    "        \"\"\"\n",
    "            Compute a mesh from the voxel volume using marching cubes.\n",
    "            Returns:\n",
    "                verts\n",
    "                faces\n",
    "                norms\n",
    "        \"\"\"\n",
    "        tsdf_vol = self.get_volume()\n",
    "\n",
    "        # Marching cubes\n",
    "        verts, faces, norms, vals = measure.marching_cubes_lewiner(tsdf_vol, level=0)\n",
    "        verts_ind = np.round(verts).astype(int)\n",
    "        \n",
    "        \"\"\"\n",
    "            Here in verts you have coordinates of voxel grid, so you need to tranfrom them to world coordinates\n",
    "            Hint: think about the offset and voxel size\n",
    "        \"\"\"\n",
    "#         verts =\n",
    "\n",
    "        return verts, faces, norms\n",
    "\n",
    "\n",
    "def rigid_transform(xyz, transform):\n",
    "    \"\"\"\n",
    "        Applies a rigid transform to an (N, 3) pointcloud.\n",
    "    \"\"\"\n",
    "    xyz_h = np.hstack([xyz, np.ones((len(xyz), 1), dtype=np.float32)])\n",
    "    xyz_t_h = np.dot(transform, xyz_h.T).T\n",
    "    return xyz_t_h[:, :3]\n",
    "\n",
    "\n",
    "def get_view_frustum(depth_im, cam_intr, cam_pose):\n",
    "    \"\"\"\n",
    "        Get corners of 3D camera view frustum of depth image\n",
    "        \n",
    "        Args:\n",
    "            depth_im: Depth\n",
    "            cam_intr: Camera intrinsics. 3x3 matrix\n",
    "            cam_pose: Camera poses. 4x4 matrix\n",
    "            \n",
    "        Return:\n",
    "            view_frustrum_points: 5x3 matrix. Contains world coordinates positions of the 5 points \\\n",
    "                                  of view frustrum associated with the camera.\n",
    "    \"\"\"\n",
    "\n",
    "    ### Create array of that 5 points in camera coordinates, in pixels. You will have 5x2 matrix\n",
    "    \n",
    "    ### Then transform them into 3d space, in camera coordinates system\n",
    "    \n",
    "    ### Then convert to world coordinates\n",
    "    view_frustrum_points = np.seros(5,3) # just a dummy\n",
    "    \n",
    "    return view_frustrum_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain TSDF $D_{i+1}$ for all observations from $1$ up to $i+1$, the TSDF from $D_{i}$ from the previous step $i$, is fused with TSDF for observation $O_{i+1}$ as follows.\n",
    "\n",
    "$$\n",
    "D_{i+1} = \\frac{W_i D_i + w_{i+1} d_{i+1}}{W_{i+1}},\n",
    "$$\n",
    "where $w_{i+1}$ is weight for TSDF constructed from the observation $O_{i+1}$.\n",
    "\n",
    "The weight $W_{i+1}$ of accumulated TSDF for is updated as:\n",
    "$$\n",
    "W_{i+1} = W_{i} + w_{i+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warmup look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project depth to world as point cloud and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
