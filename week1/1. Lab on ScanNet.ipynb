{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometric Computer Vision, Skoltech, 2021\n",
    "#### Alexey Artemov, Aleksandr Safin, Vladislav Ishimtsev\n",
    "\n",
    "<font color='red'><u>**Deadline:**</u> 23:59, February 06, 2021, (GMT +3)</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'sample_data/'\n",
    "\n",
    "import os\n",
    "import trimesh\n",
    "import k3d\n",
    "import open3d as o3d\n",
    "import imageio\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with different 3d data modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mesh\n",
    "**Task 1a. (1 point)**\n",
    "Load `sample_data/scene.ply` and visualize it as a mesh. Use `trimesh.load`, since mesh loaded with `open3d` will not have the same size as colors array provided for task 1b, since dangling vertices are not filtered for some reason in `open3d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1b. (2 points)**\n",
    "Load `sample_data/vertex_colors.npy` and use it as colors for the vertices for mesh in previous task. Visualize it and write 1-2 sentences what could these colors mean.\n",
    "\n",
    "**Hints:**\n",
    "- 1) Look at the function `k3d.mesh()` and the first, say 5 arguments\n",
    "- 2) Note that colors should be passed as list of numbers (not 3, as for RGB). The conversion from RGB is 65536 * r + 256 * g + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voxels\n",
    "\n",
    "One of the ways to represent 3d object is to stored the $SDF$ for every point in 3D grid. $SDF(p)$ - is a signed distance from the point $p$ to the boundary of 3d shape. The sign is negative if the point is inside the shape, and positive - otherwise.\n",
    "\n",
    "**Task 2. (2 points)**\n",
    "Load SDF stored in `sample_data/scene_sdf.npy`. Your task is to obtain *occupancy grid*, the voxel in occupancy grid is 1 if it belongs to 3d shape, and 0 - otherwise. We suggest you to use $0.1$ as thershold, so to find the 3d points which are near the shape boundary. \n",
    "\n",
    "Write down how many 1-valued voxels you have. And what is it's share out of the total number of voxels stored.\n",
    "\n",
    "You shold keep in mind that voxels and SDF could be obtained from meshes, point clounds, but you will do it in future labs.\n",
    "\n",
    "**Hint:**\n",
    "- Look at `k3d.voxels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put here your answers to the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGBD video\n",
    "\n",
    "ScanNet has RGBD frames, which are originally stored in `.sens` file. We have extracted some for you as RGB (`scene_frames/*_img.jpg`) + depth (`scene_frames/*_depth.png`).\n",
    "\n",
    "**Task 3. (2 points)**\n",
    "\n",
    "Load the data and plot here those RGB and depth. RGB should be in first row, and in the second row there should be corresponding depth images.\n",
    "\n",
    "The depth is depth is stored in millimeters, so you need to find maximum depth value and normalize all depth to [0,1] before visualizing so to have correct color mapping.\n",
    "\n",
    "**Hints:**\n",
    "- You could use `imageio.imread` to read the data\n",
    "- Checkout `matplotlib.pyplot` and `plt.subplot` if you do not know how to visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pointclouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4a. (1 point)**\n",
    "\n",
    "Convert occupancy grid to the point cloud. The result should have coordinates of the occupied voxels. What could be a benefit of this conversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4b. (1 points)**\n",
    "\n",
    "Another way to obtain point clouds is to sample them from the mesh. Sample 100000 points from the `sample_data/scene.ply`. It would be wise to use point_size near 0.01-0.03 for adequate visualization.\n",
    "\n",
    "**Hint:** you could try `trimesh.sample.sample_surface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position shark on the scene\n",
    "\n",
    "**Task 5a. (1 point)**\n",
    "Load mesh from `sample_data/shark.ply`\n",
    "\n",
    "Use translation equals $[3.15, 4, 0.75]$ to move shark in the scene.\n",
    "\n",
    "**Hints:** \n",
    "- 1) You would be better to use different color to plot shark mesh. Look for `color` argument of `k3d.mesh`.\n",
    "- 2) Try `.apply_translation` method of mesh onject (loaded using trimesh library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5b. (1 point)**\n",
    "Sample points from the transformed shark and plot these point cloud together with point cloud of scene from Task 4b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
